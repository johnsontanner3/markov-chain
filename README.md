REFLECT for Tanner Johnson, netID: tlj21

PART A
________________________________________
1. Examine how the k-value/order of the model, the length of the training text, and the number of characters generated affect the runtime for BruteMarkov. 
----------------------------------------
alice.txt, k = 1, 200 characters max: 0.047

alice.txt, k = 1, 400 characters max: 0.096

alice.txt, k = 1, 800 characters max: 0.136

alice.txt, k = 5, 200 characters max: 0.027

alice.txt, k = 5, 400 characters max: 0.026

alice.txt, k = 5, 800 characters max: 0.049

alice.txt, k = 10, 200 characters max: 0.026

alice.txt, k = 10, 400 characters max: 0.034

alice.txt, k = 10, 800 characters max: 0.048

hawthorne.txt, k = 1, 200 characters max: 0.359

hawthorne.txt, k = 1, 400 characters max: 0.618

hawthorne.txt, k = 1, 800 characters max: 1.268
 

-----------------------------------------
2. Based on these results, what is the relationship between the runtime and the length of the training text, the k-value, and the max characters generated? How long do you think it will take to generate 1600 random characters using an order-5 Markov model when the The Complete Works of William Shakespeare is used as the training text — our online copy of this text contains roughly 5.5 million characters. Justify your answer — don’t test empirically, use reasoning.
-----------------------------------------
According to the above results, increasing the k-value whilst holding text length and number of character constant tends to decrease runtime from k = 1 to k = 5, but slightly increases from k = 5 to k = 10. Controlling for k and generated characters shows that increasing length of training text increases runtime. Controlling for length of text and k, increasing number of characters generated increases runtime psudo-proportionally. To generate 1600 random characters using an order-5 Markov model using Shakespeare as training text would likely take about 12 seconds (assuming these data text files are written in ASCII and thus a character is equal to 1 byte). The kjv10.txt file is about 4.5 million bytes, so if the assumption holds, it is slightly smaller than the Complete Works of Shakespeare. This test for kjv10.txt takes under 11 seconds, so 12 seconds feels like a conservative guess. 



-----------------------------------------
3. Provide timings using your Efficient model for both creating the map and generating 200, 400, 800, and 1600 character random texts with an order-5 Model and alice.txt. Provide some explanation for the timings you observe.
-----------------------------------------
alice.txt, k = 5, 200 characters max: 0.077

alice.txt, k = 5, 400 characters max: 0.106

alice.txt, k = 5, 800 characters max: 0.113

alice.txt, k = 5, 1600 characters max: 0.077

Although the first three timings are systematically longer than the same tests in BruteMarkov, he last text is far faster. It's possible that EfficientMarkov setTraining is particularly prone to hash collisions. The better performance at larger numbers of characters is due to the hashing structure created in EfficientMarkov, which takes time to create, but once it's created, it's quick to access. 


-----------------------------------------
4. Provide timings for the EfficientWordMarkov with different hashcode methods. Time the method you are given and compare the results that you achieve with the better hashcode method that you developed.
-----------------------------------------
5.238 with hashcode = 32
1.729 with improved hashcode 



-----------------------------------------
5. Using a k of your choice and clinton-convention.txt as the training text, if we do not set a maximum number of characters generated (you can effectively do this by having maxLetters be a large number, e.g. 1000 times the size of the training text) what is the average number of characters generated by our Markov text generator?
-----------------------------------------
5461 characters  --  the entire text file. 



PART B

-----------------------------------------
k	Hash	Tree
1	0.391	0.768
5	1.668	4.013
10	1.791	4.325
15	1.892	4.43
20	2.055	4.697
25	2.13	4.708
30	2.085	4.839
50	3.261	5.664

tested on "data/kjv10.txt"
Timings were close for k = 1, but timings for TreeMap increased dramatically for k >= 5. 
This makes sense considering how TreeMaps are ordered by keys, and that ordering induces a cost on runtime. We don't need to know ordering for getFollows, so our HashMap will suffice, and since it doesn't maintain ordering, it's more lightweight and runs faster. 
